{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plJb8s6z32py"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 0: Montaje Drive ====\n",
        "from google.colab import drive\n",
        "# Si ya est√° montado, Colab mostrar√° mensaje. Cambia force_remount=True si quieres forzar.\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ajusta si hace falta:\n",
        "DATASET_DIR = '/content/drive/MyDrive/p_1_image'  # <-- carpeta que contiene 'benign/' y 'malignant/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtYIvTZBuoRL",
        "outputId": "fa16beb0-4655-4478-d6c0-f5ae61e30eb4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2LUN2UPjbBYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 0: Montaje Drive ====\n",
        "from google.colab import drive\n",
        "# Si ya est√° montado, Colab mostrar√° mensaje. Cambia force_remount=True si quieres forzar.\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Ajusta si hace falta:\n",
        "DATASET_DIR = '/content/drive/MyDrive/p_1_image'  # <-- carpeta que contiene 'benign/' y 'malignant/'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c498ec-c50d-4f50-d8b0-2e7e822af4f0",
        "id": "C201qW49SbGv"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 1: Instalaci√≥n dependencias (ejecutar una sola vez) ====\n",
        "# Nota: instalamos opencv-headless para poder usar cv2 en Colab\n",
        "!pip install -q tensorflow scikit-image imutils reportlab opencv-python-headless\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab426e98-d2ee-4bc3-b470-3b30275f28ff",
        "id": "sVbx3q03SbGv"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/2.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 2: Imports ====\n",
        "import os, sys, math, random, io\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "from skimage import io as skio, color, filters, feature, measure\n",
        "from skimage.transform import resize as skresize\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.preprocessing import image as kimage\n",
        "from reportlab.lib.pagesizes import landscape, A4\n",
        "from reportlab.lib.units import mm\n",
        "from reportlab.pdfgen import canvas\n",
        "from reportlab.lib import utils\n",
        "from reportlab.lib.styles import ParagraphStyle\n",
        "from reportlab.platypus import Paragraph, Frame\n",
        "from datetime import datetime\n",
        "from IPython.display import display\n",
        "from google.colab import files\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "\n",
        "# Ensure TF GPU visibility\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "id": "m8b8o1H6SbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 3: Par√°metros globales ====\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "classes = ['benign', 'malignant']\n"
      ],
      "metadata": {
        "id": "gTaNnmwASbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 4: Utilidades - load_img, compute_image_features, ensure_img_tensor, draw_image_keep_aspect ====\n",
        "def load_img(path, target_size=IMAGE_SIZE):\n",
        "    \"\"\"Carga una imagen desde disco y la devuelve como uint8 HxWx3 (numpy)\"\"\"\n",
        "    img = skio.imread(path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Imagen {path} no pudo ser leida.\")\n",
        "    if img.ndim == 2:  # grayscale\n",
        "        img = color.gray2rgb(img)\n",
        "    img_resized = skresize(img, target_size, anti_aliasing=True)\n",
        "    img_resized = (img_resized * 255).astype('uint8')\n",
        "    return img_resized\n",
        "\n",
        "def compute_image_features(img):\n",
        "    \"\"\"\n",
        "    Extrae 10 features sencillas para EDA (input: uint8 HxWx3)\n",
        "    - edge_sum: cv2.Canny sumada\n",
        "    - lbp_var: varianza del histograma LBP\n",
        "    - contrast: std del gris\n",
        "    - aspect: h / w\n",
        "    Devuelve lista de 10 valores en el orden requerido por feat_cols.\n",
        "    \"\"\"\n",
        "    arr = np.array(img)\n",
        "    if arr.ndim == 2:\n",
        "        arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    if arr.ndim != 3:\n",
        "        raise ValueError(f\"Imagen inv√°lida para features: shape {arr.shape}\")\n",
        "    # grayscale float [0,1]\n",
        "    gray = color.rgb2gray(arr)\n",
        "    mean_r = float(np.mean(arr[:, :, 0]))\n",
        "    mean_g = float(np.mean(arr[:, :, 1]))\n",
        "    mean_b = float(np.mean(arr[:, :, 2]))\n",
        "    brightness = float(np.mean(gray))\n",
        "    std_int = float(np.std(gray))\n",
        "    entropy = float(measure.shannon_entropy((gray * 255).astype('uint8')))\n",
        "    try:\n",
        "        img_gray_uint8 = (gray * 255).astype('uint8')\n",
        "        edges = cv2.Canny(img_gray_uint8, 100, 200)\n",
        "        edge_sum = float(np.sum(edges))\n",
        "    except Exception:\n",
        "        edges_sobel = filters.sobel(gray)\n",
        "        edge_sum = float(np.sum(edges_sobel))\n",
        "    try:\n",
        "        lbp = feature.local_binary_pattern((gray * 255).astype('uint8'), P=8, R=1, method='uniform')\n",
        "        lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 12), density=True)\n",
        "        lbp_var = float(np.var(lbp_hist))\n",
        "    except Exception:\n",
        "        lbp_var = float(np.var((gray * 255).astype('uint8')))\n",
        "    contrast = float(np.std((gray * 255).astype('float32')))\n",
        "    h, w = arr.shape[:2]\n",
        "    aspect = float(h / (w + 1e-9))\n",
        "    return [mean_r, mean_g, mean_b, brightness, std_int, entropy, edge_sum, lbp_var, contrast, aspect]\n",
        "\n",
        "def ensure_img_tensor(img):\n",
        "    \"\"\"A partir de PIL/np array garantiza un tensor float32 HxWx3\"\"\"\n",
        "    arr = np.array(img)\n",
        "    if arr.ndim == 2:\n",
        "        arr = np.stack([arr, arr, arr], axis=-1)\n",
        "    if arr.ndim == 4:\n",
        "        arr = arr[0]\n",
        "    if arr.ndim != 3:\n",
        "        raise ValueError(f\"Imagen inv√°lida: dimensiones {arr.shape}, se esperaba (H,W,3)\")\n",
        "    return tf.convert_to_tensor(arr, dtype=tf.float32)\n",
        "\n",
        "def draw_image_keep_aspect(c, img_array, x, y, max_width, max_height):\n",
        "    \"\"\"\n",
        "    Dibuja imagen en objeto ReportLab canvas 'c' manteniendo el aspecto.\n",
        "    img_array: numpy array HxWx3 o ruta\n",
        "    x, y: coordenada superior izquierda (reportlab origin at bottom-left)\n",
        "    \"\"\"\n",
        "    from PIL import Image\n",
        "    tmp_path = \"/tmp/_tmp_report_image.png\"\n",
        "    img = img_array\n",
        "    if isinstance(img, np.ndarray):\n",
        "        if img.ndim == 2:\n",
        "            img = np.stack([img] * 3, axis=-1)\n",
        "        pil = Image.fromarray((img).astype('uint8'))\n",
        "    else:\n",
        "        pil = Image.open(img)\n",
        "    pil.save(tmp_path, format='PNG')\n",
        "    iw, ih = utils.ImageReader(tmp_path).getSize()\n",
        "    ratio = min(max_width / iw, max_height / ih)\n",
        "    draw_w = iw * ratio\n",
        "    draw_h = ih * ratio\n",
        "    c.drawImage(tmp_path, x, y - draw_h, width=draw_w, height=draw_h, preserveAspectRatio=True, mask='auto')\n",
        "    try:\n",
        "        os.remove(tmp_path)\n",
        "    except:\n",
        "        pass\n",
        "    return draw_w, draw_h\n"
      ],
      "metadata": {
        "id": "8hX6JWFRSbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 5: Cargar paths y DataFrame ====\n",
        "paths = []\n",
        "labels = []\n",
        "for cls in classes:\n",
        "    folder = os.path.join(DATASET_DIR, cls)\n",
        "    if not os.path.exists(folder):\n",
        "        print(f\"Atenci√≥n: carpeta {folder} no existe. Revisa DATASET_DIR y nombres de clases.\")\n",
        "        continue\n",
        "    files_list = glob(os.path.join(folder, '*'))\n",
        "    for f in files_list:\n",
        "        paths.append(f)\n",
        "        labels.append(cls)\n",
        "\n",
        "df = pd.DataFrame({'path': paths, 'label': labels})\n",
        "print(\"Total im√°genes:\", len(df))\n",
        "print(df['label'].value_counts())\n"
      ],
      "metadata": {
        "id": "HoTcOBk1SbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 6: EDA completo (llamada autom√°tica) ====\n",
        "# 6.1 - Mostrar ejemplos\n",
        "def show_examples(df, n_per_class=4):\n",
        "    plt.figure(figsize=(n_per_class * 3, 6))\n",
        "    for i, cls in enumerate(classes):\n",
        "        sample = df[df['label'] == cls].sample(n=min(n_per_class, len(df[df['label'] == cls])), random_state=42).reset_index(drop=True)\n",
        "        for j, row in sample.iterrows():\n",
        "            plt.subplot(2, n_per_class, i * n_per_class + j + 1)\n",
        "            img = load_img(row['path'])\n",
        "            plt.imshow(img)\n",
        "            plt.axis('off')\n",
        "            if j == 0:\n",
        "                plt.title(cls)\n",
        "    plt.suptitle('Ejemplos por clase')\n",
        "    plt.show()\n",
        "\n",
        "# Mostrar ejemplos autom√°ticamente\n",
        "show_examples(df, n_per_class=4)\n",
        "\n",
        "# 6.2 - Extraer features para EDA\n",
        "features_list = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extrayendo features para EDA\"):\n",
        "    try:\n",
        "        img = load_img(row['path'])\n",
        "        feats = compute_image_features(img)\n",
        "    except Exception as e:\n",
        "        print(\"Error leyendo\", row['path'], e)\n",
        "        feats = [np.nan] * 10\n",
        "    features_list.append(feats)\n",
        "\n",
        "feat_cols = ['mean_r', 'mean_g', 'mean_b', 'brightness', 'std', 'entropy', 'edge_sum', 'lbp_var', 'contrast', 'aspect']\n",
        "feat_df = pd.DataFrame(features_list, columns=feat_cols)\n",
        "eda_df = pd.concat([df.reset_index(drop=True), feat_df], axis=1)\n",
        "\n",
        "# 6.3 - Estad√≠sticas y distribuci√≥n\n",
        "print(\"\\nEstad√≠sticas de features:\")\n",
        "display(eda_df[feat_cols].describe().T)\n",
        "\n",
        "print(\"\\nDistribuci√≥n de clases:\")\n",
        "display(eda_df['label'].value_counts())\n",
        "\n",
        "# Rutas\n",
        "path_benign = \"/content/drive/MyDrive/p_1_image/benign\"\n",
        "path_malign = \"/content/drive/MyDrive/p_1_image/malignant\"\n",
        "\n",
        "print(\"üìÇ ESTRUCTURA DE DIRECTORIOS:\")\n",
        "print(f\" ‚Ä¢ Ruta benigno: {path_benign}\")\n",
        "print(f\" ‚Ä¢ Ruta maligno: {path_malign}\")\n",
        "\n",
        "# Contar im√°genes\n",
        "benign_files = [f for f in os.listdir(path_benign) if f.lower().endswith(('png','jpg','jpeg'))]\n",
        "malign_files = [f for f in os.listdir(path_malign) if f.lower().endswith(('png','jpg','jpeg'))]\n",
        "\n",
        "# Distribuci√≥n por clase\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar([\"Benigno\",\"Maligno\"], [len(benign_files), len(malign_files)])\n",
        "plt.title(\"üìä DISTRIBUCI√ìN POR CLASE\")\n",
        "plt.ylabel(\"Cantidad de im√°genes\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================================\n",
        "# üìå NUEVO: AN√ÅLISIS DE CONTRASTE POR CLASE\n",
        "# ===============================================\n",
        "\n",
        "def calcular_contraste(path, files, n=50):\n",
        "    valores = []\n",
        "    for img_name in files[:n]:\n",
        "        img_path = os.path.join(path, img_name)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            valores.append(img.std())\n",
        "    return valores\n",
        "\n",
        "ben_contrast = calcular_contraste(path_benign, benign_files)\n",
        "mal_contrast = calcular_contraste(path_malign, malign_files)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.boxplot([ben_contrast, mal_contrast], labels=[\"Benigno\",\"Maligno\"])\n",
        "plt.title(\"üìà Contraste por Clase (Desviaci√≥n Est√°ndar de Intensidad)\")\n",
        "plt.ylabel(\"Contraste (std p√≠xeles)\")\n",
        "plt.show()\n",
        "\n",
        "# ===============================================\n",
        "# üìå NUEVO: HISTOGRAMAS DE INTENSIDAD POR CLASE\n",
        "# ===============================================\n",
        "\n",
        "def plot_histograms(image_paths, title):\n",
        "    plt.figure(figsize=(8,5))\n",
        "    all_pixels = []\n",
        "    for img_name in image_paths[:50]:\n",
        "        img = cv2.imread(os.path.join(path_benign if \"Benigno\" in title else path_malign, img_name),\n",
        "                         cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            all_pixels.extend(img.flatten())\n",
        "\n",
        "    plt.hist(all_pixels, bins=30, alpha=0.7)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Intensidad\")\n",
        "    plt.ylabel(\"Frecuencia\")\n",
        "    plt.show()\n",
        "\n",
        "plot_histograms(benign_files, \"üìä Histograma Intensidad ‚Äì Benigno\")\n",
        "plot_histograms(malign_files, \"üìä Histograma Intensidad ‚Äì Maligno\")\n",
        "\n",
        "# 6.4 - Matriz de correlaci√≥n con pesos en cada cuadro (annotated heatmap)\n",
        "corr = eda_df[feat_cols].corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', xticklabels=feat_cols, yticklabels=feat_cols)\n",
        "plt.title('Matriz de correlaci√≥n (con pesos en cada celda)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vgIMw-ZFSbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 7: Preparar datasets con ImageDataPipeline ====\n",
        "# Usamos image_dataset_from_directory para rapidez y facilidad (mantener etiquetas)\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATASET_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=classes,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=0.2,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    DATASET_DIR,\n",
        "    labels='inferred',\n",
        "    label_mode='categorical',\n",
        "    class_names=classes,\n",
        "    image_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    validation_split=0.2,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(AUTOTUNE)\n",
        "\n",
        "# Mostrar balance en train\n",
        "labels_list = []\n",
        "for x, y in train_ds.unbatch().as_numpy_iterator():\n",
        "    labels_list.append(np.argmax(y))\n",
        "counts = np.bincount(labels_list)\n",
        "print(\"Conteo train (benign, malignant):\", counts)\n",
        "\n",
        "# Calcular class weights\n",
        "try:\n",
        "    y_vals = np.array(labels_list)\n",
        "    class_weights = compute_class_weight('balanced', classes=np.unique(y_vals), y=y_vals)\n",
        "    class_weight_dict = {i: w for i, w in enumerate(class_weights)}\n",
        "except Exception:\n",
        "    class_weight_dict = {0: 1.0, 1: 1.0}\n",
        "print(\"Class weights:\", class_weight_dict)\n"
      ],
      "metadata": {
        "id": "rOUSHPoQSbGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 8: Modelos base (CNN transfer + RF embeddings) ====\n",
        "def build_transfer_model(input_shape=IMAGE_SIZE + (3,), base_trainable=False, dropout=0.3):\n",
        "    base = EfficientNetB0(include_top=False, input_shape=input_shape, weights='imagenet')\n",
        "    base.trainable = base_trainable\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    x = tf.keras.applications.efficientnet.preprocess_input(inputs)\n",
        "    x = base(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(2, activation='softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# CNN base (transfer learning, base frozen)\n",
        "model = build_transfer_model(base_trainable=False)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "rlp = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "\n",
        "EPOCHS = 50\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[es, rlp], class_weight=class_weight_dict)\n"
      ],
      "metadata": {
        "id": "zHq9kFxISbGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 9: Evaluaci√≥n CNN base sobre datos de validaci√≥n (convertir val_ds a arrays) ====\n",
        "val_images = []\n",
        "val_labels = []\n",
        "for x, y in val_ds.unbatch().as_numpy_iterator():\n",
        "    val_images.append(x)\n",
        "    val_labels.append(np.argmax(y))\n",
        "val_images = np.array(val_images)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "preds = model.predict(val_images)\n",
        "pred_labels = np.argmax(preds, axis=1)\n",
        "acc_cnn_base = accuracy_score(val_labels, pred_labels)\n",
        "print(\"Accuracy CNN base:\", acc_cnn_base)\n"
      ],
      "metadata": {
        "id": "rWOblZ3HSbGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 10: Extracci√≥n de embeddings para RF ====\n",
        "feature_extractor_backbone = EfficientNetB0(include_top=False, input_shape=IMAGE_SIZE + (3,), weights='imagenet')\n",
        "feature_extractor = models.Model(feature_extractor_backbone.input, layers.GlobalAveragePooling2D()(feature_extractor_backbone.output))\n",
        "feature_extractor.trainable = False\n",
        "\n",
        "X_feats = []\n",
        "y_labels = []\n",
        "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Extrayendo embeddings para RF\"):\n",
        "    img = load_img(row['path'])\n",
        "    img_arr = np.expand_dims(tf.keras.applications.efficientnet.preprocess_input(img.astype('float32')), axis=0)\n",
        "    emb = feature_extractor.predict(img_arr)\n",
        "    X_feats.append(emb.ravel())\n",
        "    y_labels.append(0 if row['label'] == 'benign' else 1)\n",
        "\n",
        "X_feats = np.array(X_feats)\n",
        "y_labels = np.array(y_labels)\n",
        "\n",
        "# Train-test split for RF\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X_feats, y_labels, test_size=0.2, random_state=42, stratify=y_labels)\n",
        "\n",
        "# Random Forest base (r√°pido)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_tr, y_tr)\n",
        "rf_pred = rf.predict(X_te)\n",
        "acc_rf_base = accuracy_score(y_te, rf_pred)\n",
        "print(\"Accuracy RF base:\", acc_rf_base)\n"
      ],
      "metadata": {
        "id": "ay4OSYSSSbGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 11: Balancear validaci√≥n para matriz de confusi√≥n CNN (1:1) ====\n",
        "def make_balanced_val(images, labels):\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    max_cnt = counts.max()\n",
        "    X_new = []\n",
        "    Y_new = []\n",
        "    for cls in np.unique(labels):\n",
        "        idxs = np.where(labels == cls)[0]\n",
        "        if len(idxs) == 0:\n",
        "            continue\n",
        "        reps = max_cnt - len(idxs)\n",
        "        X_new.extend(images[idxs].tolist())\n",
        "        Y_new.extend([cls] * len(idxs))\n",
        "        if reps > 0:\n",
        "            choice = np.random.choice(idxs, reps, replace=True)\n",
        "            X_new.extend(images[choice].tolist())\n",
        "            Y_new.extend([cls] * reps)\n",
        "    X_new = np.array(X_new)\n",
        "    Y_new = np.array(Y_new)\n",
        "    p = np.random.permutation(len(Y_new))\n",
        "    return X_new[p], Y_new[p]\n",
        "\n",
        "val_images_bal, val_labels_bal = make_balanced_val(val_images, val_labels)\n",
        "print(\"Validaci√≥n balanceada para matriz: \", np.bincount(val_labels_bal))\n"
      ],
      "metadata": {
        "id": "j0yaeDR-SbGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 13: Optimizaci√≥n simple (Fine-tuning CNN + GridSearch RF) ====\n",
        "# Guardamos accuracies antes para cuadro comparativo\n",
        "before_accuracies = {'CNN_base': acc_cnn_base, 'RF_base': acc_rf_base}\n",
        "\n",
        "# Fine-tuning CNN\n",
        "def build_transfer_model_trainable(input_shape=IMAGE_SIZE + (3,), dropout=0.4):\n",
        "    return build_transfer_model(input_shape=input_shape, base_trainable=True, dropout=dropout)\n",
        "\n",
        "model_ft = build_transfer_model_trainable(dropout=0.4)\n",
        "\n",
        "# Intentar localizar backbone para desbloquear √∫ltimas capas\n",
        "try:\n",
        "    base_backbone = model_ft.get_layer('efficientnetb0')\n",
        "except Exception:\n",
        "    base_backbone = None\n",
        "    for layer in model_ft.layers:\n",
        "        if isinstance(layer, tf.keras.Model) and 'efficientnet' in layer.name.lower():\n",
        "            base_backbone = layer\n",
        "            break\n",
        "\n",
        "if base_backbone is None:\n",
        "    for layer in model_ft.layers:\n",
        "        try:\n",
        "            if hasattr(layer.output_shape, '__len__') and len(layer.output_shape) == 4:\n",
        "                base_backbone = layer\n",
        "                break\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "num_unlock = 20\n",
        "if base_backbone is not None and hasattr(base_backbone, 'layers'):\n",
        "    total_layers = len(base_backbone.layers)\n",
        "    cutoff = max(1, total_layers - num_unlock)\n",
        "    for i, layer in enumerate(base_backbone.layers):\n",
        "        layer.trainable = True if i >= cutoff else False\n",
        "else:\n",
        "    print(\"Warning: no se encontr√≥ backbone por nombre; dejando todo como trainable=False por seguridad.\")\n",
        "    for layer in model_ft.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "model_ft.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "EPOCHS_FT = 50\n",
        "history_ft = model_ft.fit(train_ds, validation_data=val_ds, epochs=EPOCHS_FT, callbacks=[es, rlp], class_weight=class_weight_dict)\n",
        "\n",
        "# Evaluar CNN fine-tuned\n",
        "preds_ft = model_ft.predict(val_images)\n",
        "pred_labels_ft = np.argmax(preds_ft, axis=1)\n",
        "acc_cnn_ft = accuracy_score(val_labels, pred_labels_ft)\n",
        "print(\"Accuracy CNN fine-tuned:\", acc_cnn_ft)\n",
        "\n",
        "# RF tuning (GridSearch)\n",
        "param_grid = {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]}\n",
        "gs = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, n_jobs=2, scoring='accuracy')\n",
        "gs.fit(X_tr, y_tr)\n",
        "print(\"Mejores params RF:\", gs.best_params_)\n",
        "rf_best = gs.best_estimator_\n",
        "rf_pred_best = rf_best.predict(X_te)\n",
        "acc_rf_best = accuracy_score(y_te, rf_pred_best)\n",
        "print(\"Accuracy RF optimizado:\", acc_rf_best)\n"
      ],
      "metadata": {
        "id": "PI6H2ZM6SbGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 13.5: Matriz de confusi√≥n del Random Forest optimizado (solo RF) ====\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "# Asegurarnos de que rf_best y X_te, y_te existen\n",
        "try:\n",
        "    preds_rf_opt = rf_best.predict(X_te)\n",
        "    cm_rf = confusion_matrix(y_te, preds_rf_opt)\n",
        "    print(\"\\nMatriz de confusi√≥n - Random Forest (optimizado):\")\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=['benign','malignant'])\n",
        "    fig, ax = plt.subplots(figsize=(6,5))\n",
        "    disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
        "    plt.title('Confusion matrix - RF optimizado')\n",
        "    plt.show()\n",
        "\n",
        "    # Mostrar m√©tricas de clasificaci√≥n\n",
        "    print(\"\\nReporte de clasificaci√≥n (RF optimizado):\")\n",
        "    print(classification_report(y_te, preds_rf_opt, target_names=['benign','malignant']))\n",
        "except NameError as e:\n",
        "    print(\"Variable no encontrada (rf_best o X_te/y_te). Aseg√∫rate de ejecutar la celda de GridSearchCV antes de esta celda.\")\n",
        "    print(e)\n"
      ],
      "metadata": {
        "id": "9EWNOr3qSbGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 14: Resultados comparativos (antes/despu√©s) ====\n",
        "after_accuracies = {'CNN_finetune': acc_cnn_ft, 'RF_opt': acc_rf_best}\n",
        "results_table = pd.DataFrame({\n",
        "    'Modelo': ['CNN_base', 'CNN_finetune', 'RF_base', 'RF_opt'],\n",
        "    'Accuracy_before_after': [\n",
        "        before_accuracies['CNN_base'],\n",
        "        after_accuracies['CNN_finetune'],\n",
        "        before_accuracies['RF_base'],\n",
        "        after_accuracies['RF_opt']\n",
        "    ]\n",
        "})\n",
        "print(\"\\nCuadro antes/despues (accuracy):\")\n",
        "display(results_table)\n",
        "\n",
        "\n",
        "\n",
        "# ============================\n",
        "# üìå Alinear nombre del modelo final\n",
        "# ============================\n",
        "\n",
        "# Si existe \"best_model\" √∫salo\n",
        "if 'best_model' in globals():\n",
        "    model_to_save = best_model\n",
        "\n",
        "# Si existe \"grid\" y no existe best_model\n",
        "elif 'grid' in globals():\n",
        "    try:\n",
        "        model_to_save = grid.best_estimator_\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# Si existe rf (modelo random forest entrenado)\n",
        "elif 'rf' in globals():\n",
        "    model_to_save = rf\n",
        "\n",
        "# Si existe alg√∫n modelo CNN llamado \"model\"\n",
        "elif 'model' in globals():\n",
        "    model_to_save = model\n",
        "\n",
        "else:\n",
        "    raise NameError(\"‚ùå No se encontr√≥ ning√∫n modelo entrenado para guardar. Ejecuta primero la celda de entrenamiento.\")\n",
        "\n",
        "print(\"‚úÖ Modelo final alineado como: model_to_save\")\n",
        "\n",
        "# ============================\n",
        "# üìå Guardar el modelo entrenado\n",
        "# ============================\n",
        "\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "# Crear carpeta si no existe\n",
        "save_dir = \"/content/drive/MyDrive/modelos_entrenados\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Nombre versi√≥nado\n",
        "version_path = os.path.join(save_dir, f\"model_v{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\")\n",
        "\n",
        "with open(version_path, 'wb') as f:\n",
        "    pickle.dump(model_to_save, f)\n",
        "\n",
        "print(f\"üìÅ Modelo guardado como versi√≥n: {version_path}\")\n",
        "\n",
        "# Guardar tambi√©n como \"best_model.pkl\"\n",
        "best_path = os.path.join(save_dir, \"best_model.pkl\")\n",
        "\n",
        "with open(best_path, 'wb') as f:\n",
        "    pickle.dump(model_to_save, f)\n",
        "\n",
        "print(f\"üèÜ Modelo guardado como best_model.pkl\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QnrQSEEHSbGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xirfp4fXSbGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 15: Subir imagen para diagn√≥stico (alta resoluci√≥n) y predecir ====\n",
        "from google.colab import files\n",
        "print(\"Sube una imagen para diagn√≥stico (se mostrar√° en alta resoluci√≥n y se generar√° un informe A4 horizontal).\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if len(uploaded) > 0:\n",
        "    fname = list(uploaded.keys())[0]\n",
        "    img_pil = skio.imread(fname)\n",
        "    # Mostrar en alta resoluci√≥n\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    if img_pil.ndim == 2:\n",
        "        plt.imshow(img_pil, cmap='gray')\n",
        "    else:\n",
        "        plt.imshow(img_pil)\n",
        "    plt.axis('off')\n",
        "    plt.title(f'Imagen subida: {fname} (alta resoluci√≥n)')\n",
        "    plt.show()\n",
        "\n",
        "    # --- Preprocesamiento robusto (sin romper shapes) ---\n",
        "    img_np = np.array(img_pil)\n",
        "    if img_np.ndim == 2:\n",
        "        img_np = np.stack([img_np, img_np, img_np], axis=-1)\n",
        "    if img_np.ndim == 4:\n",
        "        img_np = img_np[0]\n",
        "    if img_np.ndim != 3:\n",
        "        raise ValueError(f\"Imagen inv√°lida: dimensiones {img_np.shape}, se esperaba (H,W,3)\")\n",
        "\n",
        "    # Resize y preprocess\n",
        "    img_resized = skresize(img_np, IMAGE_SIZE, anti_aliasing=True)\n",
        "    img_resized = (img_resized * 255.0).astype('float32')\n",
        "    img_proc = tf.keras.applications.efficientnet.preprocess_input(img_resized)\n",
        "\n",
        "    # Asegurar batch dimension\n",
        "    img_batch = np.expand_dims(img_proc, axis=0).astype('float32')\n",
        "\n",
        "    # Predicci√≥n CNN fine-tuned (modelo final usado)\n",
        "    prob_cnn = model_ft(img_batch, training=False).numpy()[0]\n",
        "    pred_idx_cnn = int(np.argmax(prob_cnn))\n",
        "    pred_label_cnn = classes[pred_idx_cnn]\n",
        "    prob_value_cnn = float(prob_cnn[pred_idx_cnn])\n",
        "\n",
        "    # Predicci√≥n RF sobre embeddings\n",
        "    emb = feature_extractor.predict(img_batch)\n",
        "    rf_prob = rf_best.predict_proba(emb)[0]\n",
        "    pred_idx_rf = int(np.argmax(rf_prob))\n",
        "    pred_label_rf = classes[pred_idx_rf]\n",
        "    prob_value_rf = float(rf_prob[pred_idx_rf])\n",
        "\n",
        "    # Confianza combinada (simple promedio de probabilidades en clase \"malignant\")\n",
        "    prob_malignant_combined = (prob_cnn[1] + rf_prob[1]) / 2.0\n",
        "    prob_benign_combined = 1.0 - prob_malignant_combined\n",
        "\n",
        "    print(f\"\\nPredicci√≥n CNN (fine-tuned): {pred_label_cnn} (p={prob_value_cnn:.3f})\")\n",
        "    print(f\"Predicci√≥n RF: {pred_label_rf} (p={prob_value_rf:.3f})\")\n",
        "    print(f\"Probabilidad combinada malignidad: {prob_malignant_combined:.3f}\")\n",
        "\n",
        "    # ==== CELL 16: Generar diagn√≥stico profesional en A4 horizontal con barra porcentual ====\n",
        "    out_pdf_path = '/content/drive/MyDrive/diagnostico_tiroides_informe_A4_landscape.pdf'\n",
        "    hospital_name = \"Cl√≠nica de An√°lisis Avanzado de Im√°genes (IA)\"\n",
        "    firma_text = \"Especialista\"\n",
        "    doctor_name = \"Dr./Dra. Especialista\"\n",
        "    fecha_str = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "\n",
        "    # Crear PDF (A4 landscape)\n",
        "    W, H = landscape(A4)\n",
        "    c = canvas.Canvas(out_pdf_path, pagesize=(W, H))\n",
        "    left_margin = 15 * mm\n",
        "    right_margin = 15 * mm\n",
        "    top_margin = 12 * mm\n",
        "    bottom_margin = 12 * mm\n",
        "\n",
        "    header_y = H - top_margin\n",
        "    c.setFont(\"Helvetica-Bold\", 16)\n",
        "    c.drawCentredString(W / 2, header_y, hospital_name)\n",
        "    c.setFont(\"Helvetica\", 10)\n",
        "    c.drawCentredString(W / 2, header_y - 16, \"Informe Asistido por IA - An√°lisis de Imagen Tiroidea\")\n",
        "    c.line(left_margin, header_y - 22, W - right_margin, header_y - 22)\n",
        "    c.setFont(\"Helvetica\", 8)\n",
        "    c.drawRightString(W - right_margin, header_y - 6, f\"Fecha: {fecha_str}\")\n",
        "\n",
        "    img_area_x = left_margin\n",
        "    img_area_w = (W - left_margin - right_margin) * 0.60\n",
        "    img_area_y_top = header_y - 40\n",
        "    img_area_h = H - top_margin - bottom_margin - 40\n",
        "\n",
        "    try:\n",
        "        draw_image_keep_aspect(c, img_pil if 'img_pil' in globals() else img_np, img_area_x, img_area_y_top, img_area_w, img_area_h)\n",
        "    except Exception:\n",
        "        c.setStrokeColorRGB(0.7, 0.7, 0.7)\n",
        "        c.rect(img_area_x, img_area_y_top - img_area_h, img_area_w, img_area_h)\n",
        "        c.setFont(\"Helvetica-Oblique\", 9)\n",
        "        c.drawString(img_area_x + 6, img_area_y_top - 20, \"Imagen no disponible (error al renderizar).\")\n",
        "\n",
        "    text_x = left_margin + img_area_w + 12 * mm\n",
        "    text_w = W - text_x - right_margin\n",
        "    text_y_top = img_area_y_top\n",
        "\n",
        "    c.setFont(\"Helvetica-Bold\", 14)\n",
        "    c.drawString(text_x, text_y_top, \"Informe diagn√≥stico\")\n",
        "\n",
        "    from reportlab.lib.styles import getSampleStyleSheet\n",
        "    styles = getSampleStyleSheet()\n",
        "    ps = ParagraphStyle(name='normal', fontName='Helvetica', fontSize=10, leading=12)\n",
        "    bold_ps = ParagraphStyle(name='bold', fontName='Helvetica-Bold', fontSize=11, leading=13)\n",
        "\n",
        "    result_html = f\"<b>Resultado combinado:</b> Malignidad {prob_malignant_combined * 100:.1f}% / Benigno {(1.0 - prob_malignant_combined) * 100:.1f}%\"\n",
        "    p = Paragraph(result_html, ps)\n",
        "\n",
        "    cnn_line = f\"<b>CNN (fine-tuned):</b> {pred_label_cnn} (p={prob_value_cnn:.3f})\"\n",
        "    rf_line = f\"<b>RandomForest (embeddings):</b> {pred_label_rf} (p={prob_value_rf:.3f})\"\n",
        "    p_cnn = Paragraph(cnn_line, ps)\n",
        "    p_rf = Paragraph(rf_line, ps)\n",
        "\n",
        "    if prob_malignant_combined >= 0.5:\n",
        "        suggested_action = (\"Sospecha de malignidad: Correlacionar con hallazgos cl√≠nicos y considerar biopsia (FNAB) para confirmaci√≥n histol√≥gica. \"\n",
        "                            \"Si FNAB confirma malignidad, referir a equipo oncol√≥gico/cirug√≠a seg√∫n protocolo institucional.\")\n",
        "    else:\n",
        "        suggested_action = (\"Caracter√≠sticas sugestivas de benignidad: recomendar seguimiento ecogr√°fico peri√≥dico y evaluaci√≥n cl√≠nica. \"\n",
        "                            \"Si existe crecimiento o s√≠ntomas, considerar FNAB para confirmaci√≥n.\")\n",
        "    p_reco = Paragraph(f\"<b>Recomendaci√≥n cl√≠nica:</b> {suggested_action}\", ps)\n",
        "\n",
        "    frame_height = img_area_h\n",
        "    frame = Frame(text_x, img_area_y_top - frame_height, text_w, frame_height, showBoundary=0)\n",
        "    story = [p, Paragraph(\"<br/>\", ps), p_cnn, Paragraph(\"<br/>\", ps), p_rf, Paragraph(\"<br/><br/>\", ps), p_reco]\n",
        "    frame.addFromList(story, c)\n",
        "\n",
        "    bar_x = text_x\n",
        "    bar_y = img_area_y_top - frame_height + 14 * mm\n",
        "    bar_w = text_w\n",
        "    bar_h = 10 * mm\n",
        "\n",
        "    c.setFillColorRGB(0.95, 0.95, 0.95)\n",
        "    c.rect(bar_x, bar_y, bar_w, bar_h, fill=1, stroke=0)\n",
        "\n",
        "    mal_pct = prob_malignant_combined * 100.0\n",
        "    ben_pct = 100.0 - mal_pct\n",
        "    mal_w = bar_w * (mal_pct / 100.0)\n",
        "    ben_w = bar_w - mal_w\n",
        "\n",
        "    c.setFillColorRGB(0.82, 0.1, 0.1)  # rojo\n",
        "    c.rect(bar_x, bar_y, mal_w, bar_h, fill=1, stroke=0)\n",
        "    c.setFillColorRGB(0.12, 0.55, 0.12)  # verde\n",
        "    c.rect(bar_x + mal_w, bar_y, ben_w, bar_h, fill=1, stroke=0)\n",
        "\n",
        "    c.setFont(\"Helvetica-Bold\", 9)\n",
        "    c.setFillColorRGB(0, 0, 0)\n",
        "    c.drawString(bar_x, bar_y + bar_h + 4, f\"Malignidad: {mal_pct:.1f}%    Benigno: {ben_pct:.1f}%\")\n",
        "\n",
        "    sig_x = W - right_margin - 70 * mm\n",
        "    sig_y = bottom_margin + 18 * mm\n",
        "    c.setFont(\"Times-Italic\", 12)\n",
        "    c.drawString(sig_x, sig_y + 12, firma_text)\n",
        "    c.setFont(\"Helvetica\", 9)\n",
        "    c.drawString(sig_x, sig_y - 2, doctor_name)\n",
        "    c.drawString(sig_x, sig_y - 14, \"Especialidad: Radiolog√≠a/Imagen\")\n",
        "\n",
        "    c.setFont(\"Helvetica-Oblique\", 7.5)\n",
        "    disclaimer = (\"Este informe es una ayuda al diagn√≥stico adquirido por un modelo de IA y no reemplaza la evaluaci√≥n cl√≠nica ni el informe histopatol√≥gico. \"\n",
        "                  \"Correlacionar con antecedentes y pruebas complementarias.\")\n",
        "    c.drawCentredString(W / 2, bottom_margin, disclaimer)\n",
        "\n",
        "    c.showPage()\n",
        "    c.save()\n",
        "    print(f\"\\nInforme PDF guardado en: {out_pdf_path}\")\n",
        "\n",
        "    try:\n",
        "        from IPython.display import IFrame\n",
        "        display(IFrame(out_pdf_path, width=900, height=500))\n",
        "    except Exception:\n",
        "        display(files.download(out_pdf_path))\n",
        "\n",
        "else:\n",
        "    print(\"No se subi√≥ ninguna imagen; por favor vuelve a ejecutar la celda y carga una imagen.\")\n",
        "\n",
        "\n",
        "# ==== (dentro de la misma celda de subida y predicci√≥n) ====\n",
        "# ... (toda la parte previa que ya ten√≠as: upload, preprocess, predicciones, creaci√≥n y guardado del PDF)\n",
        "# (aqu√≠ asumimos que ya se calcularon prob_malignant_combined, prob_benign_combined, pred_label_cnn, pred_label_rf, prob_value_cnn, prob_value_rf, img_np, img_pil, out_pdf_path)\n",
        "\n",
        "# (CONSERVA el c√≥digo que crea y guarda el PDF - ya lo tienes arriba)\n",
        "# Ahora: ADICIONALMENTE mostrar el diagn√≥stico profesional en la celda (imagen + texto + barra)\n",
        "\n",
        "try:\n",
        "    # Prepare left image (resized for notebook)\n",
        "    disp_img = img_np.copy() if 'img_np' in globals() else (img_pil if 'img_pil' in globals() else None)\n",
        "    if disp_img is None:\n",
        "        print(\"No hay imagen para mostrar inline.\")\n",
        "    else:\n",
        "        # Convert to uint8 and ensure shape\n",
        "        disp_img = (np.array(disp_img)).astype('uint8')\n",
        "        # Create a matplotlib figure similar to PDF layout\n",
        "        fig = plt.figure(figsize=(11,6))\n",
        "        gs = fig.add_gridspec(1, 2, width_ratios=[3,2], wspace=0.12)\n",
        "\n",
        "        # Left: image\n",
        "        ax0 = fig.add_subplot(gs[0,0])\n",
        "        ax0.imshow(disp_img)\n",
        "        ax0.axis('off')\n",
        "        ax0.set_title(f'Imagen analizada: {fname}' if 'fname' in globals() else 'Imagen analizada')\n",
        "\n",
        "        # Right: text and bar\n",
        "        ax1 = fig.add_subplot(gs[0,1])\n",
        "        ax1.axis('off')\n",
        "\n",
        "        # Text block\n",
        "        lines = [\n",
        "            f\"Informe Asistido por IA - Cl√≠nica de An√°lisis Avanzado de Im√°genes (IA)\",\n",
        "            \"\",\n",
        "            f\"Fecha: {fecha_str if 'fecha_str' in globals() else datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\",\n",
        "            \"\",\n",
        "            f\"Resultado combinado: Malignidad {prob_malignant_combined*100:.1f}%  /  Benigno {prob_benign_combined*100:.1f}%\",\n",
        "            f\"CNN (fine-tuned): {pred_label_cnn} (p={prob_value_cnn:.3f})\",\n",
        "            f\"RandomForest (embeddings): {pred_label_rf} (p={prob_value_rf:.3f})\",\n",
        "            \"\",\n",
        "            \"Recomendaci√≥n cl√≠nica:\",\n",
        "            ( \"Sospecha de malignidad: Correlacionar con hallazgos cl√≠nicos y considerar biopsia (FNAB) para confirmaci√≥n histol√≥gica.\"\n",
        "              if prob_malignant_combined >= 0.5\n",
        "              else \"Caracter√≠sticas sugestivas de benignidad: recomendar seguimiento ecogr√°fico peri√≥dico y evaluaci√≥n cl√≠nica.\")\n",
        "        ]\n",
        "\n",
        "        # Render text lines\n",
        "        y0 = 0.95\n",
        "        for line in lines:\n",
        "            ax1.text(0, y0, line, fontsize=10, va='top')\n",
        "            y0 -= 0.095\n",
        "\n",
        "        # Draw horizontal percentage bar (malignidad vs benignidad) below text\n",
        "        bar_ax = fig.add_axes([0.70, 0.10, 0.22, 0.05])  # relative coords (adjust to fit)\n",
        "        bar_ax.barh([0], [prob_malignant_combined*100], height=0.6)\n",
        "        bar_ax.barh([0], [prob_benign_combined*100], left=[prob_malignant_combined*100], height=0.6, color='green')\n",
        "        bar_ax.set_xlim(0,100)\n",
        "        bar_ax.set_yticks([])\n",
        "        bar_ax.set_xticks([0,25,50,75,100])\n",
        "        bar_ax.set_xlabel('Porcentaje (%) - Malignidad (izq) / Benigno (der)')\n",
        "        bar_ax.text(prob_malignant_combined*100 + 1, 0, f\"{prob_malignant_combined*100:.1f}% maligno\", va='center')\n",
        "\n",
        "        plt.suptitle(\"Diagn√≥stico profesional (visualizado en notebook y guardado en PDF)\", fontsize=12, weight='bold')\n",
        "        plt.show()\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Error mostrando diagn√≥stico inline:\", e)\n",
        "\n",
        "# Finalmente mostrar enlace / IFrame al PDF guardado (ya lo ten√≠as)\n",
        "try:\n",
        "    from IPython.display import IFrame\n",
        "    display(IFrame(out_pdf_path, width=900, height=500))\n",
        "except Exception:\n",
        "    display(files.download(out_pdf_path))\n"
      ],
      "metadata": {
        "id": "dz9w3tH7SbGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== CELL 17: Notas finales ====\n",
        "print(\"\\nNotas finales:\")\n",
        "print(\"- Se presenta la matriz de confusi√≥n del CNN (balanceada 1:1) con colores por cuadrante.\")\n",
        "print(\"- La matriz de correlaci√≥n muestra pesos (valores num√©ricos) en cada celda.\")\n",
        "print(\"- Se aplic√≥ fine-tuning simple al CNN y GridSearch al RF; cuadro antes/despu√©s mostrado.\")\n",
        "print(\"- El informe profesional se genera en A4 horizontal (guardado como PDF en Drive).\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YyyUvI3kSbGz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}